sep=  "," )
#limpio la memoria
rm( list=ls() )  #remove all objects
gc()             #garbage collection
require("data.table")
require("rlist")
require("rpart")
require("parallel")
#paquetes necesarios para la Bayesian Optimization
require("DiceKriging")
require("mlrMBO")
kBO_iter  <- 100   #cantidad de iteraciones de la Optimizacion Bayesiana
hs  <- makeParamSet(
makeNumericParam("cp"       , lower= -1   , upper=    0.1),
makeIntegerParam("minsplit" , lower=  1L  , upper= 8000L),  #la letra L al final significa ENTERO
makeIntegerParam("minbucket", lower=  1L  , upper= 4000L),
makeIntegerParam("maxdepth" , lower=  3L  , upper=   20L),
forbidden = quote( minbucket > 0.5*minsplit ) )             # minbuket NO PUEDE ser mayor que la mitad de minsplit
ksemilla_azar  <- 999979   #cambiar por la primer semilla
loguear  <- function( reg, arch=NA, folder="./work/", ext=".txt", verbose=TRUE )
{
archivo  <- arch
if( is.na(arch) )  archivo  <- paste0( folder, substitute( reg), ext )
if( !file.exists( archivo ) )  #Escribo los titulos
{
linea  <- paste0( "fecha\t",
paste( list.names(reg), collapse="\t" ), "\n" )
cat( linea, file=archivo )
}
linea  <- paste0( format(Sys.time(), "%Y%m%d %H%M%S"),  "\t",     #la fecha y hora
gsub( ", ", "\t", toString( reg ) ),  "\n" )
cat( linea, file=archivo, append=TRUE )  #grabo al archivo
if( verbose )  cat( linea )   #imprimo por pantalla
}
particionar  <- function( data, division, agrupa="", campo="fold", start=1, seed=NA )
{
if( !is.na( seed)  )   set.seed( seed )
bloque  <- unlist( mapply(  function(x,y) { rep( y, x ) }, division, seq( from=start, length.out=length(division) )  ) )
data[ , (campo) :=  sample( rep( bloque, ceiling(.N/length(bloque))) )[1:.N],
by= agrupa ]
}
ArbolSimple  <- function( fold_test, data, param )
{
#genero el modelo
modelo  <- rpart("clase_ternaria ~ .",
data= data[ fold != fold_test, ],  #entreno en todo MENOS el fold_test que uso para testing
xval= 0,
control= param )
#aplico el modelo a los datos de testing
prediccion  <- predict( modelo,
data[ fold==fold_test, ],  #aplico el modelo sobre los datos de testing
type= "prob")   #quiero que me devuelva probabilidades
prob_baja2  <- prediccion[, "BAJA+2"]  #esta es la probabilidad de baja
#calculo la ganancia
ganancia_testing  <- data[ fold==fold_test ][ prob_baja2 > 1/40,
sum( ifelse( clase_ternaria=="BAJA+2", 78000, -2000 ) )]
return( ganancia_testing )  #esta es la ganancia sobre el fold de testing, NO esta normalizada
}
ArbolesCrossValidation  <- function( data, param, qfolds, pagrupa, semilla )
{
divi  <- rep( 1, qfolds )  # generalmente  c(1, 1, 1, 1, 1 )  cinco unos
particionar( data, divi, seed=semilla, agrupa=pagrupa )  #particiono en dataset en folds
ganancias  <- mcmapply( ArbolSimple,
seq(qfolds), # 1 2 3 4 5
MoreArgs= list( data, param),
SIMPLIFY= FALSE,
mc.cores= 1 )   #se puede subir a qfolds si posee Linux o Mac OS
data[ , fold := NULL ]
#devuelvo la primer ganancia y el promedio
ganancia_promedio  <- mean( unlist( ganancias ) )   #promedio las ganancias
ganancia_promedio_normalizada  <- ganancia_promedio * qfolds  #aqui normalizo la ganancia
return( ganancia_promedio_normalizada )
}
EstimarGanancia  <- function( x )
{
GLOBAL_iteracion  <<-  GLOBAL_iteracion + 1
xval_folds  <- 5
ganancia  <- ArbolesCrossValidation( dataset,
param= x, #los hiperparametros del arbol
qfolds= xval_folds,  #la cantidad de folds
pagrupa= "clase_ternaria",
semilla= ksemilla_azar )
#logueo
xx  <- x
xx$xval_folds  <-  xval_folds
xx$ganancia  <- ganancia
xx$iteracion <- GLOBAL_iteracion
loguear( xx,  arch= archivo_log )
return( ganancia )
}
setwd( "C:/Users/Marcos/Documents/Maestria/dmeyf_2022" )
#cargo el dataset
dataset  <- fread("./datasets/competencia1_2022.csv")   #donde entreno
#creo la carpeta donde va el experimento
# HT  representa  Hiperparameter Tuning
dir.create( "./exp/",  showWarnings = FALSE )
dir.create( "./exp/HT3210/", showWarnings = FALSE )
setwd("./exp/HT3210/")   #Establezco el Working Directory DEL EXPERIMENTO
archivo_log  <- "HT321.txt"
archivo_BO   <- "HT321.RDATA"
#leo si ya existe el log, para retomar en caso que se se corte el programa
GLOBAL_iteracion  <- 0
if( file.exists(archivo_log) )
{
tabla_log  <- fread( archivo_log )
GLOBAL_iteracion  <- nrow( tabla_log )
}
funcion_optimizar  <- EstimarGanancia
configureMlr( show.learner.output= FALSE)
#configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar
#por favor, no desesperarse por lo complejo
obj.fun  <- makeSingleObjectiveFunction(
fn=       funcion_optimizar,
minimize= FALSE,   #estoy Maximizando la ganancia
noisy=    TRUE,
par.set=  hs,
has.simple.signature = FALSE
)
ctrl  <- makeMBOControl( save.on.disk.at.time= 600,  save.file.path= archivo_BO)
ctrl  <- setMBOControlTermination(ctrl, iters= kBO_iter )
ctrl  <- setMBOControlInfill(ctrl, crit= makeMBOInfillCritEI())
surr.km  <- makeLearner("regr.km", predict.type= "se", covtype= "matern3_2", control= list(trace= TRUE))
#inicio la optimizacion bayesiana
if( !file.exists( archivo_BO ) ) {
run  <- mbo( fun=     obj.fun,
learner= surr.km,
control= ctrl)
} else  run  <- mboContinue( archivo_BO )   #retomo en caso que ya exista
#limpio la memoria
rm( list=ls() )  #remove all objects
gc()             #garbage collection
#cargo las librerias que necesito
require("data.table")
require("rpart")
require("rpart.plot")
#Aqui se debe poner la carpeta de la materia de SU computadora local
setwd("C:/Users/Marcos/Documents/Maestria/dmeyf_2022")  #Establezco el Working Directory
#cargo el dataset
dataset  <- fread("./datasets/competencia1_2022.csv")
dtrain  <- dataset[ foto_mes==202101 ]  #defino donde voy a entrenar
dapply  <- dataset[ foto_mes==202103 ]  #defino donde voy a aplicar el modelo
#genero el modelo,  aqui se construye el arbol
modelo  <- rpart(formula=   "clase_ternaria ~ .",  #quiero predecir clase_ternaria a partir de el resto de las variables
data=      dtrain,  #los datos donde voy a entrenar
xval=      0,
cp=       -0.877390142,   #esto significa no limitar la complejidad de los splits
minsplit=  854,     #minima cantidad de registros para que se haga el split
minbucket= 74,     #tamaño minimo de una hoja
maxdepth=  8 )    #profundidad maxima del arbol
#aplico el modelo a los datos nuevos
prediccion  <- predict( object= modelo,
newdata= dapply,
type = "prob")
#agrego a dapply una columna nueva que es la probabilidad de BAJA+2
dapply[ , prob_baja2 := prediccion[, "BAJA+2"] ]
#solo le envio estimulo a los registros con probabilidad de BAJA+2 mayor  a  1/40
dapply[ , Predicted := as.numeric( prob_baja2 > 1/40 ) ]
fwrite( dapply[ , list(numero_de_cliente, Predicted) ], #solo los campos para Kaggle
file= "./exp/HT3210/HT321_001.csv",
sep=  "," )
#limpio la memoria
rm( list=ls() )  #remove all objects
gc()             #garbage collection
#cargo las librerias que necesito
require("data.table")
require("rpart")
require("rpart.plot")
#Aqui se debe poner la carpeta de la materia de SU computadora local
setwd("C:/Users/Marcos/Documents/Maestria/dmeyf_2022")  #Establezco el Working Directory
#cargo el dataset
dataset  <- fread("./datasets/competencia1_2022.csv")
dtrain  <- dataset[ foto_mes==202101 ]  #defino donde voy a entrenar
dapply  <- dataset[ foto_mes==202103 ]  #defino donde voy a aplicar el modelo
#genero el modelo,  aqui se construye el arbol
modelo  <- rpart(formula=   "clase_ternaria ~ .",  #quiero predecir clase_ternaria a partir de el resto de las variables
data=      dtrain,  #los datos donde voy a entrenar
xval=      0,
cp=       -0.3,   #esto significa no limitar la complejidad de los splits
minsplit=  0,     #minima cantidad de registros para que se haga el split
minbucket= 1,     #tamaño minimo de una hoja
maxdepth=  4 )    #profundidad maxima del arbol
#grafico el arbol
prp(modelo, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
#limpio la memoria
rm( list=ls() )  #remove all objects
gc()             #garbage collection
#cargo las librerias que necesito
require("data.table")
require("rpart")
require("rpart.plot")
#Aqui se debe poner la carpeta de la materia de SU computadora local
setwd("C:/Users/Marcos/Documents/Maestria/dmeyf_2022")  #Establezco el Working Directory
#cargo el dataset
dataset  <- fread("./datasets/competencia1_2022.csv")
#elimino la variable más importante del arbol (ctrx_quater)
dataset_alt <- dataset[ , !"ctrx_quarter", with=FALSE]
#para no cambiar todo el scrip, vuelvo a ponerle el nombre original para correr el arbol corto
dataset <- dataset_alt
dtrain  <- dataset[ foto_mes==202101 ]  #defino donde voy a entrenar
dapply  <- dataset[ foto_mes==202103 ]  #defino donde voy a aplicar el modelo
#genero el modelo max_dept=3,  aqui se construye el arbol
modelo_3  <- rpart(formula=   "clase_ternaria ~ .",  #quiero predecir clase_ternaria a partir de el resto de las variables
data=      dtrain,  #los datos donde voy a entrenar
xval=      0,
cp=       -0.725637875,   #esto significa no limitar la complejidad de los splits
minsplit=  278,     #minima cantidad de registros para que se haga el split
minbucket= 138,     #tamaño minimo de una hoja
maxdepth=  3 )    #profundidad maxima del arbol
#grafico el arbol
prp(modelo_3, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
#limpio la memoria
rm( list=ls() )  #remove all objects
gc()             #garbage collection
#cargo las librerias que necesito
require("data.table")
require("rpart")
require("rpart.plot")
#Aqui se debe poner la carpeta de la materia de SU computadora local
setwd("C:/Users/Marcos/Documents/Maestria/dmeyf_2022")  #Establezco el Working Directory
#cargo el dataset
dataset  <- fread("./datasets/competencia1_2022.csv")
#elimino la variable más importante del arbol (ctrx_quater)
dataset_alt <- dataset[ , !"ctrx_quarter", with=FALSE]
#para no cambiar todo el scrip, vuelvo a ponerle el nombre original para correr el arbol corto
dataset <- dataset_alt
dtrain  <- dataset[ foto_mes==202101 ]  #defino donde voy a entrenar
dapply  <- dataset[ foto_mes==202103 ]  #defino donde voy a aplicar el modelo
#genero el modelo max_dept=3,  aqui se construye el arbol
modelo  <- rpart(formula=   "clase_ternaria ~ .",  #quiero predecir clase_ternaria a partir de el resto de las variables
data=      dtrain,  #los datos donde voy a entrenar
xval=      0,
cp=       -0.079946355,   #esto significa no limitar la complejidad de los splits
minsplit=  3399,     #minima cantidad de registros para que se haga el split
minbucket= 1689,     #tamaño minimo de una hoja
maxdepth=  4 )    #profundidad maxima del arbol
#grafico el arbol
prp(modelo, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
#limpio la memoria
rm( list=ls() )  #remove all objects
gc()             #garbage collection
#cargo las librerias que necesito
require("data.table")
require("rpart")
require("rpart.plot")
#Aqui se debe poner la carpeta de la materia de SU computadora local
setwd("C:/Users/Marcos/Documents/Maestria/dmeyf_2022")  #Establezco el Working Directory
#cargo el dataset
dataset  <- fread("./datasets/competencia1_2022.csv")
dataset[ , campo1 := as.integer( ctrx_quarter <14 & active_quarter == 0 & mcuentas_saldo < -1558.3 & cdescubierto_preacordado = 0 ) ]
dataset[ , campo1 := as.integer( ctrx_quarter <14 & active_quarter == 0 & mcuentas_saldo < -1558.3 & cdescubierto_preacordado == 0 ) ]
dataset[ , campo2 := as.integer( ctrx_quarter <14 & active_quarter == 0 & mcuentas_saldo < -1558.3 & cdescubierto_preacordado == 1 ) ]
dataset[ , campo3 := as.integer( ctrx_quarter <14 & active_quarter == 0 & mcuentas_saldo >= -1558.3 & cdescubierto_preacordado == 0 ) ]
dataset[ , campo4 := as.integer( ctrx_quarter <14 & active_quarter == 0 & mcuentas_saldo < -1558.3 & cdescubierto_preacordado == 1 ) ]
dataset[ , campo5 := as.integer( ctrx_quarter <14 & active_quarter == 1 & Visa_status >= 8 & mprestamos_personales < 13879 ) ]
dataset[ , campo6 := as.integer( ctrx_quarter <14 & active_quarter == 1 & Visa_status >= 8 & mprestamos_personales >= 13879 ) ]
dataset[ , campo7 := as.integer( ctrx_quarter <14 & active_quarter == 1 & Visa_status < 8 & mpasivos_margen < 112.5 ) ]
dataset[ , campo8 := as.integer( ctrx_quarter <14 & active_quarter == 1 & Visa_status < 8 & mpasivos_margen >= 112.5 ) ]
View(dataset)
fwrite(dataset, file="./datasets/pedo.csv")
#cargo las librerias que necesito
require("data.table")
require("rpart")
require("rpart.plot")
#limpio la memoria
rm( list=ls() )  #remove all objects
gc()             #garbage collection
#cargo las librerias que necesito
require("data.table")
require("rpart")
require("rpart.plot")
#Aqui se debe poner la carpeta de la materia de SU computadora local
setwd("C:/Users/Marcos/Documents/Maestria/dmeyf_2022")  #Establezco el Working Directory
#cargo el dataset
dataset  <- fread("./datasets/competencia1_2022.csv" )
#creo la clase_binaria SI={ BAJA+1, BAJA+2 }    NO={ CONTINUA }
dataset[ foto_mes==202101,
clase_binaria :=  ifelse( clase_ternaria=="CONTINUA", "NO", "SI" ) ]
dtrain  <- dataset[ foto_mes==202101 ]  #defino donde voy a entrenar
dapply  <- dataset[ foto_mes==202103 ]  #defino donde voy a aplicar el modelo
modelo  <- rpart(formula=   "clase_binaria ~ . -clase_ternaria",
data=      dtrain,  #los datos donde voy a entrenar
xval=         0,
cp=          -0.54,#  -0.89
minsplit=  1073,   # 621
minbucket=  278,   # 309
maxdepth=     9 )  #  12
#aplico el modelo a los datos nuevos
prediccion  <- predict( object=  modelo,
newdata= dapply,
type = "prob")
#agrego a dapply una columna nueva que es la probabilidad de BAJA+2
dfinal  <- copy( dapply[ , list(numero_de_cliente) ] )
dfinal[ , prob_SI := prediccion[ , "SI"] ]
# por favor cambiar por una semilla propia
# que sino el Fiscal General va a impugnar la prediccion
set.seed(999979)
dfinal[ , azar := runif( nrow(dapply) ) ]
# ordeno en forma descentente, y cuando coincide la probabilidad, al azar
setorder( dfinal, -prob_SI, azar )
dir.create( "./exp/" )
dir.create( "./exp/KA4120" )
for( corte  in  c( 7500, 8000, 8500, 9000, 9500, 10000, 10500, 11000 ) )
{
#le envio a los  corte  mejores,  de mayor probabilidad de prob_SI
dfinal[ , Predicted := 0L ]
dfinal[ 1:corte , Predicted := 1L ]
fwrite( dfinal[ , list(numero_de_cliente, Predicted) ], #solo los campos para Kaggle
file= paste0( "./exp/KA4120/KA4120_005_",  corte, ".csv"),
sep=  "," )
}
#limpio la memoria
rm( list=ls() )  #remove all objects
gc()             #garbage collection
#cargo las librerias que necesito
require("data.table")
require("rpart")
require("rpart.plot")
#Aqui se debe poner la carpeta de la materia de SU computadora local
setwd("C:/Users/Marcos/Documents/Maestria/dmeyf_2022")  #Establezco el Working Directory
#cargo el dataset
dataset  <- fread("./datasets/competencia1_2022.csv")
dataset[ , clase_binaria:= ifelse(clase_ternaria=='CONTINUA',
'NEG',
'POS')]
dtrain  <- dataset[ foto_mes==202101 ]  #defino donde voy a entrenar
dapply  <- dataset[ foto_mes==202103 ]  #defino donde voy a aplicar el modelo
#genero el modelo max_dept=3,  aqui se construye el arbol
modelo  <- rpart(formula=   "clase_ternaria ~ .",  #quiero predecir clase_ternaria a partir de el resto de las variables
data=      dtrain,  #los datos donde voy a entrenar
xval=      0,
cp=       -0.079946355,   #esto significa no limitar la complejidad de los splits
minsplit=  3399,     #minima cantidad de registros para que se haga el split
minbucket= 1689,     #tamaño minimo de una hoja
maxdepth=  4 )    #profundidad maxima del arbol
#grafico el arbol
prp(modelo, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
rm(modelo)
#genero el modelo max_dept=3,  aqui se construye el arbol
modelo  <- rpart(formula=   "clase_ternaria ~ .",  #quiero predecir clase_ternaria a partir de el resto de las variables
data=      dtrain,  #los datos donde voy a entrenar
xval=      0,
cp=       -0.3,   #esto significa no limitar la complejidad de los splits
minsplit=  0,     #minima cantidad de registros para que se haga el split
minbucket= 1,     #tamaño minimo de una hoja
maxdepth=  4 )    #profundidad maxima del arbol
#grafico el arbol
prp(modelo, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
rm(modelo)
#genero el modelo max_dept=3,  aqui se construye el arbol
modelo  <- rpart(formula=   "clase_binaria ~ . -clase_ternaria",  #quiero predecir clase_ternaria a partir de el resto de las variables
data=      dtrain,  #los datos donde voy a entrenar
xval=      0,
cp=       -0.3,   #esto significa no limitar la complejidad de los splits
minsplit=  0,     #minima cantidad de registros para que se haga el split
minbucket= 1,     #tamaño minimo de una hoja
maxdepth=  4 )    #profundidad maxima del arbol
#grafico el arbol
prp(modelo, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
#limpio la memoria
rm( list=ls() )  #remove all objects
gc()             #garbage collection
#cargo las librerias que necesito
require("data.table")
require("rpart")
require("rpart.plot")
#Aqui se debe poner la carpeta de la materia de SU computadora local
setwd("C:/Users/Marcos/Documents/Maestria/dmeyf_2022")  #Establezco el Working Directory
#cargo el dataset
dataset  <- fread("./datasets/competencia1_2022.csv")
dataset[ , clase_binaria:= ifelse(clase_ternaria=='CONTINUA',
'NEG',
'POS')]
dataset[ , clase:= ifelse(foto_mes=='202101',
'enero',
'marzo')]
View(dataset)
dtrain  <- dataset[ foto_mes==202101 ]  #defino donde voy a entrenar
dapply  <- dataset[ foto_mes==202103 ]  #defino donde voy a aplicar el modelo
#genero el modelo max_dept=3,  aqui se construye el arbol
modelo  <- rpart(formula=   "clase_binaria ~ . -clase_ternaria",  #quiero predecir clase_ternaria a partir de el resto de las variables
data=      dtrain,  #los datos donde voy a entrenar
xval=      0,
cp=       -0.3,   #esto significa no limitar la complejidad de los splits
minsplit=  0,     #minima cantidad de registros para que se haga el split
minbucket= 1,     #tamaño minimo de una hoja
maxdepth=  4 )    #profundidad maxima del arbol
#grafico el arbol
prp(modelo, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
rm(modelo)
#genero el modelo max_dept=3,  aqui se construye el arbol
modelo  <- rpart(formula=   "clase ~ . -clase_ternaria",  #quiero predecir clase_ternaria a partir de el resto de las variables
data=      dtrain,  #los datos donde voy a entrenar
xval=      0,
cp=       -0.3,   #esto significa no limitar la complejidad de los splits
minsplit=  0,     #minima cantidad de registros para que se haga el split
minbucket= 1,     #tamaño minimo de una hoja
maxdepth=  4 )    #profundidad maxima del arbol
#limpio la memoria
rm( list=ls() )  #remove all objects
gc()             #garbage collection
#cargo las librerias que necesito
require("data.table")
require("rpart")
require("rpart.plot")
#Aqui se debe poner la carpeta de la materia de SU computadora local
setwd("C:/Users/Marcos/Documents/Maestria/dmeyf_2022")  #Establezco el Working Directory
#cargo el dataset
dataset  <- fread("./datasets/competencia1_2022.csv")
dataset[ , clase:= ifelse(foto_mes=='202101',
'enero',
'marzo')]
dtrain  <- dataset[ foto_mes==202101 ]  #defino donde voy a entrenar
dapply  <- dataset[ foto_mes==202103 ]  #defino donde voy a aplicar el modelo
#genero el modelo max_dept=3,  aqui se construye el arbol
modelo  <- rpart(formula=   "clase ~ . -clase_ternaria",  #quiero predecir clase_ternaria a partir de el resto de las variables
data=      dtrain,  #los datos donde voy a entrenar
xval=      0,
cp=       -0.3,   #esto significa no limitar la complejidad de los splits
minsplit=  0,     #minima cantidad de registros para que se haga el split
minbucket= 1,     #tamaño minimo de una hoja
maxdepth=  4 )    #profundidad maxima del arbol
dtrain <- dataset
#genero el modelo max_dept=3,  aqui se construye el arbol
modelo  <- rpart(formula=   "clase ~ . -clase_ternaria",  #quiero predecir clase_ternaria a partir de el resto de las variables
data=      dtrain,  #los datos donde voy a entrenar
xval=      0,
cp=       -0.3,   #esto significa no limitar la complejidad de los splits
minsplit=  0,     #minima cantidad de registros para que se haga el split
minbucket= 1,     #tamaño minimo de una hoja
maxdepth=  4 )    #profundidad maxima del arbol
#grafico el arbol
prp(modelo, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
#genero el modelo max_dept=3,  aqui se construye el arbol
modelo  <- rpart(formula=   "clase ~ . -clase_ternaria",  #quiero predecir clase_ternaria a partir de el resto de las variables
data=      dtrain,  #los datos donde voy a entrenar
xval=      0,
cp=       -0.3,   #esto significa no limitar la complejidad de los splits
minsplit=  0,     #minima cantidad de registros para que se haga el split
minbucket= 1,     #tamaño minimo de una hoja
maxdepth=  20 )    #profundidad maxima del arbol
#grafico el arbol
prp(modelo, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
#genero el modelo max_dept=3,  aqui se construye el arbol
modelo  <- rpart(formula=   "clase ~ . -clase_ternaria",  #quiero predecir clase_ternaria a partir de el resto de las variables
data=      dtrain,  #los datos donde voy a entrenar
xval=      0,
cp=       -0.3,   #esto significa no limitar la complejidad de los splits
minsplit=  10,     #minima cantidad de registros para que se haga el split
minbucket= 2,     #tamaño minimo de una hoja
maxdepth=  20 )    #profundidad maxima del arbol
#grafico el arbol
prp(modelo, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
#genero el modelo max_dept=3,  aqui se construye el arbol
modelo  <- rpart(formula=   "clase ~ . -clase_ternaria - foto_mes",  #quiero predecir clase_ternaria a partir de el resto de las variables
data=      dtrain,  #los datos donde voy a entrenar
xval=      0,
cp=       -0.3,   #esto significa no limitar la complejidad de los splits
minsplit=  10,     #minima cantidad de registros para que se haga el split
minbucket= 2,     #tamaño minimo de una hoja
maxdepth=  20 )    #profundidad maxima del arbol
#grafico el arbol
prp(modelo, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
#limpio la memoria
rm( list=ls() )  #remove all objects
gc()             #garbage collection
#cargo las librerias que necesito
require("data.table")
require("rpart")
require("rpart.plot")
#Aqui se debe poner la carpeta de la materia de SU computadora local
setwd("C:/Users/Marcos/Documents/Maestria/dmeyf_2022")  #Establezco el Working Directory
#cargo el dataset
dataset  <- fread("./datasets/competencia1_2022.csv")
dataset[ , clase:= ifelse(foto_mes=='202101',
'enero',
'marzo')]
dtrain <- dataset
#genero el modelo max_dept=3,  aqui se construye el arbol
modelo  <- rpart(formula=   "clase ~ . -clase_ternaria - foto_mes",  #quiero predecir clase_ternaria a partir de el resto de las variables
data=      dtrain,  #los datos donde voy a entrenar
xval=      0,
cp=       -0.3,   #esto significa no limitar la complejidad de los splits
minsplit=  0,     #minima cantidad de registros para que se haga el split
minbucket= 1,     #tamaño minimo de una hoja
maxdepth=  5 )    #profundidad maxima del arbol
#grafico el arbol
prp(modelo, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
gc()
require("data.table")
DT <- data.table(A=1:5)
View(DT)
DT[ , X := shift(A, 1, type="lag")]
View(DT)
DT[ , Y := shift(A, 1, type="lead")]
View(DT)
pru <- data.table(mtcars)
pru[, cyl_gear2 := cyl + gear]
View(pru)
pru[,  `:=`(cyl_gear3 = cyl * gear, cyl_gear4 = cyl - gear)]
View(pru)
pru[,  .(cyl_gear5 = cyl * gear, cyl_gear6 = cyl - gear)]
View(pru)
pru[,  .(cyl_gear3 = cyl * gear, cyl_gear4 = cyl - gear)]
pru[, .(mean_mileage=mean(mpg)), by=cyl]
pru[, .SD, by=cyl]
pru <- data.table(mtcars)
pru[, .SD, by=cyl]
mtcars_dt <- data.table(mtcars)
mtcars_dt[, .SD, by=cyl]
mtcars_dt
output <- mtcars_dt[, lapply(.SD[, 1:10, with=F], mean), by=cyl]
output
