#cargo el dataset
dataset  <- fread("./datasets/competencia1_2022.csv" )
#creo la clase_binaria SI={ BAJA+1, BAJA+2 }    NO={ CONTINUA }
dataset[ foto_mes==202101,
clase_binaria :=  ifelse( clase_ternaria=="CONTINUA", "NO", "SI" ) ]
dtrain  <- dataset[ foto_mes==202101 ]  #defino donde voy a entrenar
dapply  <- dataset[ foto_mes==202103 ]  #defino donde voy a aplicar el modelo
modelo  <- rpart(formula=   "clase_binaria ~ . -clase_ternaria",
data=      dtrain,  #los datos donde voy a entrenar
xval=         0,
cp=          -0.54,#  -0.89
minsplit=  1073,   # 621
minbucket=  278,   # 309
maxdepth=     9 )  #  12
#aplico el modelo a los datos nuevos
prediccion  <- predict( object=  modelo,
newdata= dapply,
type = "prob")
#agrego a dapply una columna nueva que es la probabilidad de BAJA+2
dfinal  <- copy( dapply[ , list(numero_de_cliente) ] )
dfinal[ , prob_SI := prediccion[ , "SI"] ]
# por favor cambiar por una semilla propia
# que sino el Fiscal General va a impugnar la prediccion
set.seed(999979)
dfinal[ , azar := runif( nrow(dapply) ) ]
# ordeno en forma descentente, y cuando coincide la probabilidad, al azar
setorder( dfinal, -prob_SI, azar )
dir.create( "./exp/" )
dir.create( "./exp/KA4120" )
for( corte  in  c( 7500, 8000, 8500, 9000, 9500, 10000, 10500, 11000 ) )
{
#le envio a los  corte  mejores,  de mayor probabilidad de prob_SI
dfinal[ , Predicted := 0L ]
dfinal[ 1:corte , Predicted := 1L ]
fwrite( dfinal[ , list(numero_de_cliente, Predicted) ], #solo los campos para Kaggle
file= paste0( "./exp/KA4120/KA4120_005_",  corte, ".csv"),
sep=  "," )
}
#limpio la memoria
rm( list=ls() )  #remove all objects
gc()             #garbage collection
#cargo las librerias que necesito
require("data.table")
require("rpart")
require("rpart.plot")
#Aqui se debe poner la carpeta de la materia de SU computadora local
setwd("C:/Users/Marcos/Documents/Maestria/dmeyf_2022")  #Establezco el Working Directory
#cargo el dataset
dataset  <- fread("./datasets/competencia1_2022.csv")
dataset[ , clase_binaria:= ifelse(clase_ternaria=='CONTINUA',
'NEG',
'POS')]
dtrain  <- dataset[ foto_mes==202101 ]  #defino donde voy a entrenar
dapply  <- dataset[ foto_mes==202103 ]  #defino donde voy a aplicar el modelo
#genero el modelo max_dept=3,  aqui se construye el arbol
modelo  <- rpart(formula=   "clase_ternaria ~ .",  #quiero predecir clase_ternaria a partir de el resto de las variables
data=      dtrain,  #los datos donde voy a entrenar
xval=      0,
cp=       -0.079946355,   #esto significa no limitar la complejidad de los splits
minsplit=  3399,     #minima cantidad de registros para que se haga el split
minbucket= 1689,     #tamaño minimo de una hoja
maxdepth=  4 )    #profundidad maxima del arbol
#grafico el arbol
prp(modelo, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
rm(modelo)
#genero el modelo max_dept=3,  aqui se construye el arbol
modelo  <- rpart(formula=   "clase_ternaria ~ .",  #quiero predecir clase_ternaria a partir de el resto de las variables
data=      dtrain,  #los datos donde voy a entrenar
xval=      0,
cp=       -0.3,   #esto significa no limitar la complejidad de los splits
minsplit=  0,     #minima cantidad de registros para que se haga el split
minbucket= 1,     #tamaño minimo de una hoja
maxdepth=  4 )    #profundidad maxima del arbol
#grafico el arbol
prp(modelo, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
rm(modelo)
#genero el modelo max_dept=3,  aqui se construye el arbol
modelo  <- rpart(formula=   "clase_binaria ~ . -clase_ternaria",  #quiero predecir clase_ternaria a partir de el resto de las variables
data=      dtrain,  #los datos donde voy a entrenar
xval=      0,
cp=       -0.3,   #esto significa no limitar la complejidad de los splits
minsplit=  0,     #minima cantidad de registros para que se haga el split
minbucket= 1,     #tamaño minimo de una hoja
maxdepth=  4 )    #profundidad maxima del arbol
#grafico el arbol
prp(modelo, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
#limpio la memoria
rm( list=ls() )  #remove all objects
gc()             #garbage collection
#cargo las librerias que necesito
require("data.table")
require("rpart")
require("rpart.plot")
#Aqui se debe poner la carpeta de la materia de SU computadora local
setwd("C:/Users/Marcos/Documents/Maestria/dmeyf_2022")  #Establezco el Working Directory
#cargo el dataset
dataset  <- fread("./datasets/competencia1_2022.csv")
dataset[ , clase_binaria:= ifelse(clase_ternaria=='CONTINUA',
'NEG',
'POS')]
dataset[ , clase:= ifelse(foto_mes=='202101',
'enero',
'marzo')]
View(dataset)
dtrain  <- dataset[ foto_mes==202101 ]  #defino donde voy a entrenar
dapply  <- dataset[ foto_mes==202103 ]  #defino donde voy a aplicar el modelo
#genero el modelo max_dept=3,  aqui se construye el arbol
modelo  <- rpart(formula=   "clase_binaria ~ . -clase_ternaria",  #quiero predecir clase_ternaria a partir de el resto de las variables
data=      dtrain,  #los datos donde voy a entrenar
xval=      0,
cp=       -0.3,   #esto significa no limitar la complejidad de los splits
minsplit=  0,     #minima cantidad de registros para que se haga el split
minbucket= 1,     #tamaño minimo de una hoja
maxdepth=  4 )    #profundidad maxima del arbol
#grafico el arbol
prp(modelo, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
rm(modelo)
#genero el modelo max_dept=3,  aqui se construye el arbol
modelo  <- rpart(formula=   "clase ~ . -clase_ternaria",  #quiero predecir clase_ternaria a partir de el resto de las variables
data=      dtrain,  #los datos donde voy a entrenar
xval=      0,
cp=       -0.3,   #esto significa no limitar la complejidad de los splits
minsplit=  0,     #minima cantidad de registros para que se haga el split
minbucket= 1,     #tamaño minimo de una hoja
maxdepth=  4 )    #profundidad maxima del arbol
#limpio la memoria
rm( list=ls() )  #remove all objects
gc()             #garbage collection
#cargo las librerias que necesito
require("data.table")
require("rpart")
require("rpart.plot")
#Aqui se debe poner la carpeta de la materia de SU computadora local
setwd("C:/Users/Marcos/Documents/Maestria/dmeyf_2022")  #Establezco el Working Directory
#cargo el dataset
dataset  <- fread("./datasets/competencia1_2022.csv")
dataset[ , clase:= ifelse(foto_mes=='202101',
'enero',
'marzo')]
dtrain  <- dataset[ foto_mes==202101 ]  #defino donde voy a entrenar
dapply  <- dataset[ foto_mes==202103 ]  #defino donde voy a aplicar el modelo
#genero el modelo max_dept=3,  aqui se construye el arbol
modelo  <- rpart(formula=   "clase ~ . -clase_ternaria",  #quiero predecir clase_ternaria a partir de el resto de las variables
data=      dtrain,  #los datos donde voy a entrenar
xval=      0,
cp=       -0.3,   #esto significa no limitar la complejidad de los splits
minsplit=  0,     #minima cantidad de registros para que se haga el split
minbucket= 1,     #tamaño minimo de una hoja
maxdepth=  4 )    #profundidad maxima del arbol
dtrain <- dataset
#genero el modelo max_dept=3,  aqui se construye el arbol
modelo  <- rpart(formula=   "clase ~ . -clase_ternaria",  #quiero predecir clase_ternaria a partir de el resto de las variables
data=      dtrain,  #los datos donde voy a entrenar
xval=      0,
cp=       -0.3,   #esto significa no limitar la complejidad de los splits
minsplit=  0,     #minima cantidad de registros para que se haga el split
minbucket= 1,     #tamaño minimo de una hoja
maxdepth=  4 )    #profundidad maxima del arbol
#grafico el arbol
prp(modelo, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
#genero el modelo max_dept=3,  aqui se construye el arbol
modelo  <- rpart(formula=   "clase ~ . -clase_ternaria",  #quiero predecir clase_ternaria a partir de el resto de las variables
data=      dtrain,  #los datos donde voy a entrenar
xval=      0,
cp=       -0.3,   #esto significa no limitar la complejidad de los splits
minsplit=  0,     #minima cantidad de registros para que se haga el split
minbucket= 1,     #tamaño minimo de una hoja
maxdepth=  20 )    #profundidad maxima del arbol
#grafico el arbol
prp(modelo, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
#genero el modelo max_dept=3,  aqui se construye el arbol
modelo  <- rpart(formula=   "clase ~ . -clase_ternaria",  #quiero predecir clase_ternaria a partir de el resto de las variables
data=      dtrain,  #los datos donde voy a entrenar
xval=      0,
cp=       -0.3,   #esto significa no limitar la complejidad de los splits
minsplit=  10,     #minima cantidad de registros para que se haga el split
minbucket= 2,     #tamaño minimo de una hoja
maxdepth=  20 )    #profundidad maxima del arbol
#grafico el arbol
prp(modelo, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
#genero el modelo max_dept=3,  aqui se construye el arbol
modelo  <- rpart(formula=   "clase ~ . -clase_ternaria - foto_mes",  #quiero predecir clase_ternaria a partir de el resto de las variables
data=      dtrain,  #los datos donde voy a entrenar
xval=      0,
cp=       -0.3,   #esto significa no limitar la complejidad de los splits
minsplit=  10,     #minima cantidad de registros para que se haga el split
minbucket= 2,     #tamaño minimo de una hoja
maxdepth=  20 )    #profundidad maxima del arbol
#grafico el arbol
prp(modelo, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
#limpio la memoria
rm( list=ls() )  #remove all objects
gc()             #garbage collection
#cargo las librerias que necesito
require("data.table")
require("rpart")
require("rpart.plot")
#Aqui se debe poner la carpeta de la materia de SU computadora local
setwd("C:/Users/Marcos/Documents/Maestria/dmeyf_2022")  #Establezco el Working Directory
#cargo el dataset
dataset  <- fread("./datasets/competencia1_2022.csv")
dataset[ , clase:= ifelse(foto_mes=='202101',
'enero',
'marzo')]
dtrain <- dataset
#genero el modelo max_dept=3,  aqui se construye el arbol
modelo  <- rpart(formula=   "clase ~ . -clase_ternaria - foto_mes",  #quiero predecir clase_ternaria a partir de el resto de las variables
data=      dtrain,  #los datos donde voy a entrenar
xval=      0,
cp=       -0.3,   #esto significa no limitar la complejidad de los splits
minsplit=  0,     #minima cantidad de registros para que se haga el split
minbucket= 1,     #tamaño minimo de una hoja
maxdepth=  5 )    #profundidad maxima del arbol
#grafico el arbol
prp(modelo, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
gc()
require("data.table")
DT <- data.table(A=1:5)
View(DT)
DT[ , X := shift(A, 1, type="lag")]
View(DT)
DT[ , Y := shift(A, 1, type="lead")]
View(DT)
pru <- data.table(mtcars)
pru[, cyl_gear2 := cyl + gear]
View(pru)
pru[,  `:=`(cyl_gear3 = cyl * gear, cyl_gear4 = cyl - gear)]
View(pru)
pru[,  .(cyl_gear5 = cyl * gear, cyl_gear6 = cyl - gear)]
View(pru)
pru[,  .(cyl_gear3 = cyl * gear, cyl_gear4 = cyl - gear)]
pru[, .(mean_mileage=mean(mpg)), by=cyl]
pru[, .SD, by=cyl]
pru <- data.table(mtcars)
pru[, .SD, by=cyl]
mtcars_dt <- data.table(mtcars)
mtcars_dt[, .SD, by=cyl]
mtcars_dt
output <- mtcars_dt[, lapply(.SD[, 1:10, with=F], mean), by=cyl]
output
#limpio la memoria
rm( list=ls() )  #remove all objects
#limpio la memoria
rm( list=ls() )  #remove all objects
gc()             #garbage collection
#cargo las librerias que necesito
require("data.table")
require("rpart")
require("rpart.plot")
#Aqui se debe poner la carpeta de la materia de SU computadora local
setwd("C:/Users/Marcos/Documents/Maestria/dmeyf_2022")  #Establezco el Working Directory
#cargo el dataset
dataset  <- fread("./datasets/competencia1_2022.csv")
dataset <- dataset[ , ctrx_quarter_bis := ctrx_quarter]
dtrain  <- dataset[ foto_mes==202101 ]  #defino donde voy a entrenar
dapply  <- dataset[ foto_mes==202103 ]  #defino donde voy a aplicar el modelo
#genero el modelo,  aqui se construye el arbol
modelo  <- rpart(formula=   "clase_ternaria ~ .",  #quiero predecir clase_ternaria a partir de el resto de las variables
data=      dtrain,  #los datos donde voy a entrenar
xval=      0,
cp=       -0.877390142,   #esto significa no limitar la complejidad de los splits
minsplit=  854,     #minima cantidad de registros para que se haga el split
minbucket= 74,     #tamaño minimo de una hoja
maxdepth=  8 )    #profundidad maxima del arbol
modelo$variable.importance
prp(modelo, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
#cargo las librerias que necesito
require("data.table")
require("rpart")
require("rpart.plot")
#Aqui se debe poner la carpeta de la materia de SU computadora local
setwd("C:/Users/Marcos/Documents/Maestria/dmeyf_2022")  #Establezco el Working Directory
#cargo el dataset
dataset  <- fread("./datasets/competencia1_2022.csv" )
dataset[ , campo1 := as.integer( ctrx_quarter <14 & mcuentas_saldo < -1256.1 & cprestamos_personales <2 ) ]
dataset[ , campo2 := as.integer( ctrx_quarter <14 & mcuentas_saldo < -1256.1 & cprestamos_personales>=2 ) ]
dataset[ , campo3 := as.integer( ctrx_quarter <14 & mcuentas_saldo>= -1256.1 & mcaja_ahorro <2601.1 ) ]
dataset[ , campo4 := as.integer( ctrx_quarter <14 & mcuentas_saldo>= -1256.1 & mcaja_ahorro>=2601.1 ) ]
dataset[ , campo5 := as.integer( ctrx_quarter>=14 & ctrx_quarter<30  & mcaja_ahorro<2604.3  ) ]
dataset[ , campo6 := as.integer( ctrx_quarter>=14 & ctrx_quarter<30  & mcaja_ahorro>=2604.3  ) ]
dataset[ , campo7 := as.integer( ctrx_quarter>=14 & ctrx_quarter>=30  & ctrx_quarter<49  ) ]
dataset[ , campo8 := as.integer( ctrx_quarter>=14 & ctrx_quarter>=30  & ctrx_quarter>=49  ) ]
#creo la clase_binaria SI={ BAJA+1, BAJA+2 }    NO={ CONTINUA }
dataset[ foto_mes==202101,
clase_binaria :=  ifelse( clase_ternaria=="CONTINUA", "NO", "SI" ) ]
dtrain  <- dataset[ foto_mes==202101 ]  #defino donde voy a entrenar
dapply  <- dataset[ foto_mes==202103 ]  #defino donde voy a aplicar el modelo
modelo  <- rpart(formula=   "clase_binaria ~ . -clase_ternaria",
data=      dtrain,  #los datos donde voy a entrenar
xval=         0,
cp=          -0.54,#  -0.89
minsplit=  1073,   # 621
minbucket=  278,   # 309
maxdepth=     9 )  #  12
View(modelo)
# corrijo manualmente el drifting de  Visa_fultimo_cierre
dapply[ Visa_fultimo_cierre== 1, Visa_fultimo_cierre :=  4 ]
dapply[ Visa_fultimo_cierre== 7, Visa_fultimo_cierre := 11 ]
dapply[ Visa_fultimo_cierre==21, Visa_fultimo_cierre := 25 ]
dapply[ Visa_fultimo_cierre==14, Visa_fultimo_cierre := 18 ]
dapply[ Visa_fultimo_cierre==28, Visa_fultimo_cierre := 32 ]
dapply[ Visa_fultimo_cierre==35, Visa_fultimo_cierre := 39 ]
dapply[ Visa_fultimo_cierre> 39, Visa_fultimo_cierre := Visa_fultimo_cierre + 4 ]
# corrijo manualmente el drifting de  Visa_fultimo_cierre
dapply[ Master_fultimo_cierre== 1, Master_fultimo_cierre :=  4 ]
dapply[ Master_fultimo_cierre== 7, Master_fultimo_cierre := 11 ]
dapply[ Master_fultimo_cierre==21, Master_fultimo_cierre := 25 ]
dapply[ Master_fultimo_cierre==14, Master_fultimo_cierre := 18 ]
dapply[ Master_fultimo_cierre==28, Master_fultimo_cierre := 32 ]
dapply[ Master_fultimo_cierre==35, Master_fultimo_cierre := 39 ]
dapply[ Master_fultimo_cierre> 39, Master_fultimo_cierre := Master_fultimo_cierre + 4 ]
#aplico el modelo a los datos nuevos
prediccion  <- predict( object=  modelo,
newdata= dapply,
type = "prob")
View(prediccion)
dapply[ , list(numero_de_cliente)
dapply[ , list(numero_de_cliente) ]
dapply[ , numero_de_cliente ]
library(data.table)
mt <- fread("https://raw.githubusercontent.com/selva86/datasets/master/mtcars.csv")
head(mt)
class(mt)
mtcars_dt[1:4, list(mpg, cyl, gear)]
mt[1:4, list(mpg, cyl, gear)]
mt[, list(mpg, cyl, gear)]
mt[1:5, list(mpg)]
mt[1:5, mpg]
#agrego a dapply una columna nueva que es la probabilidad de BAJA+2
dfinal  <- copy( dapply[ , list(numero_de_cliente) ] )
View(dfinal)
dfinal[ , prob_SI := prediccion[ , "SI"] ]
View(dfinal)
# por favor cambiar por una semilla propia
# que sino el Fiscal General va a impugnar la prediccion
set.seed(388699)
dfinal[ , azar := runif( nrow(dapply) ) ]
View(dfinal)
library(data.table)
mt <- fread("https://raw.githubusercontent.com/selva86/datasets/master/mtcars.csv")
head(mt)
class(mt)
mt[, rank_wt:=frank(wt)]
View(mt)
View(mt)
mt[, as.integer(rank_wt:=frank(wt))]
mt[, rank_wt:=as.integer(frank(wt))]
View(mt)
#limpio la memoria
rm( list=ls() )  #Borro todos los objetos
gc()   #Garbage Collection
require("data.table")
require("rpart")
require("rpart.plot")
#Aqui se debe poner la carpeta de la computadora local
setwd("C:/Users/Marcos/Documents/Maestria/dmeyf_2022")  #Establezco el Working Directory
#cargo los datos donde entreno
dataset  <- fread("./datasets/competencia2_2022.csv.gz")
dtrain  <- dataset[ foto_mes==202103 ]
dapply  <- dataset[ foto_mes==202105 ]
#Establezco cuales son los campos que puedo usar para la prediccion
campos_buenos  <- setdiff(  colnames(dtrain) ,  c("clase_ternaria") )
param_buenos  <- list( "cp"=         -1,
"minsplit"=  300,
"minbucket"= 150,
"maxdepth"=    6 )
num_trees         <- 200    #voy a generar 200 arboles, a mas arboles mas tiempo de proceso y MEJOR MODELO
feature_fraction  <-   0.5  #entreno cada arbol con solo 50% de las variables variables
set.seed(102191) #Establezco la semilla aleatoria, cambiar por SU primer semilla
set.seed(999979) #Establezco la semilla aleatoria, cambiar por SU primer semilla
#inicializo en CERO el vector de las probabilidades en dapply
#Aqui es donde voy acumulando, sumando, las probabilidades
probabilidad_ensemble  <- rep( 0, nrow(dapply) )
tb_ensembles  <-  copy( dapply[ , list( numero_de_cliente ) ] )
#genero el archivo para Kaggle
#creo la carpeta donde va el experimento
dir.create( "./exp/", showWarnings = FALSE  )
dir.create( "./exp/KA6210/", showWarnings = FALSE )
#aqui es donde voy a graficar los arboles
pdf( "./exp/KA6210/arbolitos.pdf", paper="a4r" )
for(  i in  1:num_trees ) #genero  num_trees arboles
{
qty_campos_a_utilizar  <- as.integer( length(campos_buenos)* feature_fraction )
campos_random  <- sample( campos_buenos, qty_campos_a_utilizar )
#paso de un vector a un string con los elementos separados por un signo de "+"
#este hace falta para la formula
campos_random  <- paste( campos_random, collapse=" + ")
#armo la formula para rpart
formulita  <- paste0( "clase_ternaria ~ ", campos_random )
#genero el arbol de decision
modelo  <- rpart( formulita,
data= dtrain,
xval= 0,
control= param_buenos )
#grafico el modelo
prp(modelo, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
#aplico el modelo a los datos que no tienen clase
prediccion  <- predict( modelo, dapply , type = "prob")
tb_ensembles[  ,  paste0( "arbol", i) :=  prediccion[ , "BAJA+2"] ]
#voy acumulando la probabilidad
probabilidad_ensemble  <- probabilidad_ensemble +  prediccion[, "BAJA+2"]
}
dev.off()  #dejo de imprimir
#fue sumando las probabilidades, ahora hago el cociente por la cantidad de arboles
#o sea, calculo el promedio
probabilidad_ensemble  <- probabilidad_ensemble / num_trees
#asigngo el promedio y grabo
tb_ensembles[  , prob_promedio := probabilidad_ensemble ]
fwrite( tb_ensembles,
file="./exp/KA6210/ensemble.csv",
sep="\t" )
#Genero la entrega para Kaggle
entrega  <- as.data.table( list( "numero_de_cliente"= dapply[  , numero_de_cliente],
"Predicted"= as.numeric(probabilidad_ensemble > 1/40) ) ) #genero la salida
#genero el archivo para Kaggle
#creo la carpeta donde va el experimento
dir.create( "./exp/", showWarnings = FALSE  )
dir.create( "./exp/KA6210/", showWarnings = FALSE )
#grabo el archivo para Kaggle
fwrite( entrega,
file= "./exp/KA6210/KA6210_001.csv",
sep= "," )
#limpio la memoria
rm( list=ls() )  #remove all objects
gc()             #garbage collection
require("data.table")
require("lightgbm")
#defino los parametros de la corrida, en una lista, la variable global  PARAM
#  muy pronto esto se leera desde un archivo formato .yaml
PARAM <- list()
PARAM$experimento  <- "KA7240"
PARAM$input$dataset       <- "./datasets/competencia2_2022.csv.gz"
PARAM$input$training      <- c( 202103 )
PARAM$input$future        <- c( 202105 )
PARAM$finalmodel$max_bin           <-     31
PARAM$finalmodel$learning_rate     <-      0.0280015981   #0.0142501265
PARAM$finalmodel$num_iterations    <-    328  #615
PARAM$finalmodel$num_leaves        <-   1015  #784
PARAM$finalmodel$min_data_in_leaf  <-   5542  #5628
PARAM$finalmodel$feature_fraction  <-      0.7832319551  #0.8382482539
PARAM$finalmodel$semilla           <- 102191
#------------------------------------------------------------------------------
#------------------------------------------------------------------------------
#Aqui empieza el programa
setwd( "C:/Users/Marcos/Documents/Maestria/dmeyf_2022" )
#cargo el dataset donde voy a entrenar
dataset  <- fread(PARAM$input$dataset, stringsAsFactors= TRUE)
#paso la clase a binaria que tome valores {0,1}  enteros
#set trabaja con la clase  POS = { BAJA+1, BAJA+2 }
#esta estrategia es MUY importante
dataset[ , clase01 := ifelse( clase_ternaria %in%  c("BAJA+2","BAJA+1"), 1L, 0L) ]
#los campos que se van a utilizar
campos_buenos  <- setdiff( colnames(dataset), c("clase_ternaria","clase01") )
#establezco donde entreno
dataset[ , train  := 0L ]
dataset[ foto_mes %in% PARAM$input$training, train  := 1L ]
#--------------------------------------
#creo las carpetas donde van los resultados
#creo la carpeta donde va el experimento
# HT  representa  Hiperparameter Tuning
dir.create( "./exp/",  showWarnings = FALSE )
dir.create( paste0("./exp/", PARAM$experimento, "/" ), showWarnings = FALSE )
setwd( paste0("./exp/", PARAM$experimento, "/" ) )   #Establezco el Working Directory DEL EXPERIMENTO
#dejo los datos en el formato que necesita LightGBM
dtrain  <- lgb.Dataset( data= data.matrix(  dataset[ train==1L, campos_buenos, with=FALSE]),
label= dataset[ train==1L, clase01] )
#genero el modelo
#estos hiperparametros  salieron de una laaarga Optmizacion Bayesiana
modelo  <- lgb.train( data= dtrain,
param= list( objective=          "binary",
max_bin=            PARAM$finalmodel$max_bin,
learning_rate=      PARAM$finalmodel$learning_rate,
num_iterations=     PARAM$finalmodel$num_iterations,
num_leaves=         PARAM$finalmodel$num_leaves,
min_data_in_leaf=   PARAM$finalmodel$min_data_in_leaf,
feature_fraction=   PARAM$finalmodel$feature_fraction,
seed=               PARAM$finalmodel$semilla
)
)
#--------------------------------------
#ahora imprimo la importancia de variables
tb_importancia  <-  as.data.table( lgb.importance(modelo) )
archivo_importancia  <- "impo.txt"
fwrite( tb_importancia,
file= archivo_importancia,
sep= "\t" )
#aplico el modelo a los datos sin clase
dapply  <- dataset[ foto_mes== PARAM$input$future ]
#aplico el modelo a los datos nuevos
prediccion  <- predict( modelo,
data.matrix( dapply[, campos_buenos, with=FALSE ])                                 )
#genero la tabla de entrega
tb_entrega  <-  dapply[ , list( numero_de_cliente, foto_mes ) ]
tb_entrega[  , prob := prediccion ]
#grabo las probabilidad del modelo
fwrite( tb_entrega,
file= "prediccion.txt",
sep= "\t" )
#ordeno por probabilidad descendente
setorder( tb_entrega, -prob )
#genero archivos con los  "envios" mejores
#deben subirse "inteligentemente" a Kaggle para no malgastar submits
cortes <- seq( 5000, 12000, by=500 )
for( envios  in  cortes )
{
tb_entrega[  , Predicted := 0L ]
tb_entrega[ 1:envios, Predicted := 1L ]
fwrite( tb_entrega[ , list(numero_de_cliente, Predicted)],
file= paste0(  PARAM$experimento, "_", envios, ".csv" ),
sep= "," )
}
quit( save= "no" )
